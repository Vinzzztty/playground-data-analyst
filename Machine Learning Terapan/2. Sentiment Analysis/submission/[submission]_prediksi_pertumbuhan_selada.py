# -*- coding: utf-8 -*-
"""[Submission]_Prediksi_Pertumbuhan_Selada.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v4ZBitJvg6vCjh9hgHM2BCfT_LTvBQXM

# Proyek Machine Learning: Prediksi Pertumbuhan Selada Dengan Algoritma Machine Learning

- **Nama:** Kevin Arnandes
- **Email:** kevinarnandes21@gmail.com
- **ID Dicoding:** kevinarnandes

## Import Semua Packages/Library yang Digunakan
"""

"""Data Preparation Library"""
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, KFold
import numpy as np

"""Models Library"""
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
    precision_score,
    recall_score,
    f1_score,
)
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import mean_squared_error
from sklearn.svm import SVC, SVR
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor

"""Model Evaluation"""
from sklearn.model_selection import cross_val_score

"""Other"""
import warnings
from sklearn.utils._testing import ignore_warnings
from sklearn.exceptions import ConvergenceWarning

warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=ConvergenceWarning)

"""## Data Wrangling

### Gathering Data
"""

# Load Dataset
url = "https://raw.githubusercontent.com/Vinzzztty/playground-data-analyst/main/Machine%20Learning%20Terapan/2.%20Sentiment%20Analysis/dataset/dataset_selada.csv"
df = pd.read_csv(url)

df.head(5)

df.sample(5)

# Melihat baris dari terakhir pada dataframe

df.tail()

"""### Assessing Data

#### Melihat semua kolom pada dataframe
"""

# Show Column in dataframe
df.columns

"""#### Melihat tipe data dari dataframe"""

# Cek tipe data dari dataframe
df.info()

"""Dari output terlihat bahwa:
- Terdapat 1 kolom tipe object yaitu Label
- Terdapat 4 kolom numerik dengan tipe data float64 yaitu: Jam, temperature, pH, WaterTemp
- Terdapat 5 kolom numerik edngan tipe data int64 yaitu: humidity, light, EC, TDS, Pattern
"""

# Cek nilai numerik
df.describe()

"""#### Cek Missing Value dan data kosong"""

# Check null data
df.isnull().sum()

# Check NaN data
df.isna().sum()

"""#### Assessing Specific Column seperti kolom Label, Pattern, dan Temperature"""

# Cek nilai unik pada kolom Label
df["Label"].value_counts()

# Melihat nilai unik pada kolom Pattern
df["Pattern"].value_counts()

"""##### Melihat nilai pada kolom temperature yang lebih besar dari 100"""

# Filter baris dengan nilai 'temperature' lebih besar dari 100
high_temperature_rows = df[df["temperature"] > 100]

# Tampilkan nilai pada kolom 'temperature' dari baris yang telah difilter
high_temperature_values = high_temperature_rows["temperature"]
print("Nilai kolom 'temperature' yang lebih besar dari 100:")
print(high_temperature_values)

"""## Exploratory Data Analysis (EDA)

### Melihat Banyak Nilai pada Kolom Pattern
"""

# Hitung jumlah setiap nilai dalam kolom 'Pattern'
pattern_counts = df["Pattern"].value_counts()

print(pattern_counts)

# Hitung jumlah setiap nilai dalam kolom 'Pattern'
pattern_counts = df["Pattern"].value_counts()

# Plot bar chart
plt.figure(figsize=(10, 6))
pattern_counts.plot(kind="bar", color="skyblue")
plt.title("Jumlah Setiap Pola dalam Data")
plt.xlabel("Pattern")
plt.ylabel("Jumlah")
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability
plt.tight_layout()
plt.show()

"""### Mencari Korelasi Kolom"""

# Membuat Matrix Korelasi
cor_matrix = df[
    ["temperature", "humidity", "light", "pH", "EC", "TDS", "WaterTemp", "Pattern"]
].corr()
cor_matrix

# Heatmap of the correlation matrix
plt.figure(figsize=(15, 5))
sns.heatmap(cor_matrix, annot=True, cmap="YlGnBu", fmt=".2f", linewidths=0.5)
plt.title("Correlation Matrix")
plt.show()

"""EC dan TDS memiliki korelasi yang sangat baik yaitu Positif 1

## Data Preparation

### Cleaning Data

#### Menangani Kesalahan Penulisan Nilai pada Kolom temperature
"""

# Jika ada baris dengan nilai 'temperature' lebih dari 100.00, lakukan perbaikan
if not high_temperature_rows.empty:
    # Perbaiki nilai 'temperature' dengan membaginya dengan 100
    df.loc[df["temperature"] > 100.00, "temperature"] /= 100.0

# Cek dataframe apakah nilai temperature sudah benar dengan melihat min dan max
df.describe()

"""#### Handling Outliers

##### Visualisasi Boxplot
"""

sns.boxplot(x=df["temperature"])

sns.boxplot(x=df["humidity"])

sns.boxplot(x=df["light"])

sns.boxplot(x=df["pH"])

sns.boxplot(x=df["EC"])

sns.boxplot(x=df["TDS"])

sns.boxplot(x=df["WaterTemp"])

"""##### Menangani Outlier dengan IQR"""

# Tentukan kolom yang akan dipertimbangkan
kolom_yang_dipertimbangkan = [
    "temperature",
    "humidity",
    "light",
    "pH",
    "EC",
    "TDS",
    "WaterTemp",
]

# Hitung IQR untuk kolom-kolom yang sudah ditentukan
Q1 = df[kolom_yang_dipertimbangkan].quantile(0.25)
Q3 = df[kolom_yang_dipertimbangkan].quantile(0.75)
IQR = Q3 - Q1

# Filter outlier untuk kolom-kolom yang sudah ditentukan
insurance = df[
    ~(
        (df[kolom_yang_dipertimbangkan] < (Q1 - 1.5 * IQR))
        | (df[kolom_yang_dipertimbangkan] > (Q3 + 1.5 * IQR))
    ).any(axis=1)
]

# Periksa ukuran dataset setelah menghapus outlier
insurance.shape

"""#### Drop Not Important Column"""

df = df.drop(columns=["Jam", "Label"])

df.head()

"""### Data PreProcessing"""

# Membuat fitur-fitur yang akan digunakan
fitur = ["temperature", "humidity", "light", "pH", "EC", "TDS", "WaterTemp"]

# Mengganti nilai-nilai dalam DataFrame
X = df[fitur]

# Variabel Target
y = df["Pattern"]

# Display first 5 rows
X.head()

"""#### Split Data to Train and Test 80:20"""

# Memisahkan data menjadi data latih dan data uji dengan perbandingan 80% dan 20%
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Menampilkan jumlah total sampel dalam dataset keseluruhan
print(f"Total # of sample in whole dataset: {len(X)}")

# Menampilkan jumlah total sampel dalam dataset latih
print(f"Total # of sample in train dataset: {len(X_train)}")

# Menampilkan jumlah total sampel dalam dataset uji
print(f"Total # of sample in test dataset: {len(X_test)}")

"""### Standarisasi
Mengubah setiap fitur dalam data sehingga memiliki mean 0 dan standar deviasi 1.
"""

# Memeriksa kolom-kolom non-numeric
kolom_non_numerik = X.select_dtypes(exclude=["float64", "int64"]).columns
print("Kolom non-numeric:", kolom_non_numerik)

# Standard Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""## Model Deployment

Dengan Default Parameter

### Deklarasi variabel Models
"""

# Train Models
models = {
    "Gradient Boosting Classifier": GradientBoostingClassifier(),
    "Random Forest": RandomForestClassifier(),
    "Support Vector Machine": SVC(),
    "K-Nearest Neighbors": KNeighborsClassifier(),
}

"""#### Membuat variabel list untuk menyimpan hasil train models"""

# Create an empty list to store results
results_list = []

"""#### Melakukan training klasifikasi model"""

# Classification Model Reports
for name, model in models.items():
    # Assuming models is a dictionary containing your classifier instances
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Calculate accuracy
    accuracy = accuracy_score(y_test, y_pred)

    # Generate classification report
    report_dict = classification_report(y_test, y_pred, output_dict=True)

    # Extract precision, recall, and f1-score
    precision = report_dict["weighted avg"]["precision"]
    recall = report_dict["weighted avg"]["recall"]
    f1_score = report_dict["weighted avg"]["f1-score"]

    # Append results to list
    results_list.append(
        {
            "Model": name,
            "Accuracy": accuracy,
            "Precision": precision,
            "Recall": recall,
            "F1 Score": f1_score,
        }
    )

"""#### Membuat dataframe baru bernama results_train_df yang berisi nilai dari list results_list"""

# Convert list of dictionaries to DataFrame
results_train_df = pd.DataFrame(results_list)

"""## Model Evaluation

### Display Akurasi masing masing model
"""

results_train_df

"""#### Visualisasi hasil train model yang disimpan di variabel results_train_df menggunakan library matplotlib"""

# Set 'Model' column as index
results_train_df.set_index("Model", inplace=True)

# Plot the DataFrame
results_train_df.plot(kind="bar")

# Set plot labels and title
plt.xlabel("Model")
plt.ylabel("Metrics")
plt.title("Performance Metrics by Model")

# Show the plot
plt.show()

"""### Menambahkan Hyperparameter masing masing model

#### Membuat variabel list baru bernama new_results_list untuk menyimpan hasil train model dengan hyperparameter tunning
"""

new_results_list = []

"""#### Deklrasi model dengan hyperparameter tunning"""

new_models = {
    "Gradient Boosting Classifier": GradientBoostingClassifier(
        learning_rate=0.1, max_depth=10
    ),
    "Random Forest": RandomForestClassifier(n_estimators=100, max_depth=30),
    "Support Vector Machine": SVC(C=10.0, kernel="rbf", gamma="scale"),
    "K-Nearest Neighbors": KNeighborsClassifier(n_neighbors=5, weights="distance", p=1),
}

"""#### Melakukan train model hyperparameter tunning"""

# Classification Model Reports
for name, model in new_models.items():
    # Assuming models is a dictionary containing your classifier instances
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Calculate accuracy
    accuracy = accuracy_score(y_test, y_pred)

    # Generate classification report
    report_dict = classification_report(y_test, y_pred, output_dict=True)

    # Extract precision, recall, and f1-score
    precision = report_dict["weighted avg"]["precision"]
    recall = report_dict["weighted avg"]["recall"]
    f1_score = report_dict["weighted avg"]["f1-score"]

    # Append results to list
    new_results_list.append(
        {
            "New Model": name,
            "New Accuracy": accuracy,
            "New Precision": precision,
            "New Recall": recall,
            "New F1 Score": f1_score,
        }
    )

"""#### Convert hasil train model hyperparameter tunning ke dalam dataframe baru new_results_train_df"""

# Convert list of dictionaries to DataFrame
new_results_train_df = pd.DataFrame(new_results_list)

"""#### Melihat hasil dataframe new_results_train_df"""

# Display dataframe
new_results_train_df

"""### Visualisasi Perbandingan Model

Model sebelum di hyperparameter tunning dengan model hyperparameter tunning

#### Menggabungkan dataframe sebelum tunning dan sesudah tunning
"""

combined_df = pd.concat([results_train_df, new_results_train_df], axis=1)

"""#### Drop not important column"""

# Drop not important column
combined_df.drop(
    columns=[
        "New Model",
        "Precision",
        "Recall",
        "F1 Score",
        "New Precision",
        "New Recall",
        "New F1 Score",
    ],
    inplace=True,
)

combined_df

"""#### Membuat visualisasi perbandingan Model dengan parameternya adalah akurasi"""

# Set 'Model' column as index
combined_df.set_index("Model", inplace=True)

# Plot the DataFrame
combined_df.plot(kind="bar", figsize=(10, 6))

# Set plot labels and title
plt.xlabel("Model")
plt.ylabel("Accuracy")
plt.title("Comparison of Accuracy and New Accuracy for Each Model")

# Rotate x-axis labels for better readability
plt.xticks(rotation=45, ha="right")

# Show the plot
plt.tight_layout()
plt.show()

## Predict
# User input
print("Enter values for the following features:")
input_values = {}
for feature in X.columns:
    value = float(input(f"{feature}: "))
    input_values[feature] = value

# Make predictions using new models and store in a DataFrame
prediction_results = {"Model": [], "Prediction": []}
for name, model in new_models.items():
    prediction = model.predict(scaler.transform(pd.DataFrame([input_values])))
    prediction_results["Model"].append(name)
    prediction_results["Prediction"].append(prediction[0])

# Create a DataFrame from the results
prediction_df = pd.DataFrame(prediction_results)

# Display the prediction table
print("\nPrediction Results:")
print(prediction_df)
